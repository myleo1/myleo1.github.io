[{"categories":["Golang"],"content":"概述 在Go语言中，Map是常用的数据类型之一，其底层与其他语言类似，其底层使用哈希表作为数据结构，而使用哈希表，最重要的是解决哈希冲突，Go与其他大多数语言一样，使用拉链法解决哈希冲突，其细节不再赘述，此文重点解析Map底层的数据结构以及其实现。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:1:0","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"数据结构 Go 语言运行时同时使用了多个数据结构组合表示哈希表，其中 runtime.hmap 是最核心的结构体，我们先来了解一下该结构体的内部字段： type hmap struct { count int //表示当前哈希表中的元素数量 flags uint8 B uint8 //表示当前哈希表持有的bucket数量，因为都是2的倍数，该字段存储对数，也就是len(buckets)==2^B noverflow uint16 hash0 uint32 //哈希的种子，为哈希函数引入随机性，创建哈希表时确定 buckets unsafe.Pointer oldbuckets unsafe.Pointer //哈希在扩容时用于保存之前的buckets字段，它的大小是当前buckets的一半 nevacuate uintptr extra *mapextra } type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap } 如上图所示哈希表 runtime.hmap 的桶是 runtime.bmap。每一个 runtime.bmap 都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 extra.nextOverflow 中桶存储溢出的数据。 上述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶，上图中黄色的 runtime.bmap 就是正常桶，绿色的 runtime.bmap 是溢出桶，溢出桶是在 Go 语言还使用 C 语言实现时使用的设计，由于它能够减少扩容的频率所以一直使用至今。 桶的结构体 runtime.bmap 在 Go 语言源代码中的定义只包含一个简单的 tophash 字段，tophash 存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能： type bmap struct { tophash [bucketCnt]uint8 } 在运行期间，runtime.bmap 结构体其实不止包含 tophash 字段，因为哈希表中可能存储不同类型的键值对。runtime.bmap 中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的 cmd/compile/internal/gc.bmap 函数重建它的结构： type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } 随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。 从 Go 语言哈希的定义中可以发现，改进元素比数组和切片复杂得多，它的结构体中不仅包含大量字段，还使用复杂的嵌套结构，后面的小节会详细介绍不同字段的作用。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:2:0","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"初始化 Go语言初始化哈希分成两种方法，一种是通过字面量，另一种是通过运行时。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:3:0","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"字面量 目前的现代编程语言基本都支持使用字面量的方式初始化哈希，一般都会使用 key: value 的语法来表示键值对，Go 语言中也不例外： hash := map[string]int{ \"1\": 2, \"3\": 4, \"5\": 6, } 我们需要在初始化哈希时声明键值对的类型，这种使用字面量初始化的方式最终都会通过 cmd/compile/internal/gc.maplit 初始化，我们来分析一下该函数初始化哈希的过程： func maplit(n *Node, m *Node, init *Nodes) { a := nod(OMAKE, nil, nil) a.Esc = n.Esc a.List.Set2(typenod(n.Type), nodintconst(int64(n.List.Len()))) litas(m, a, init) entries := n.List.Slice() if len(entries) \u003e 25 { ... return } // Build list of var[c] = expr. // Use temporaries so that mapassign1 can have addressable key, elem. ... } 当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： hash := make(map[string]int, 3) hash[\"1\"] = 2 hash[\"3\"] = 4 hash[\"5\"] = 6 这种初始化的方式与数组和切片几乎完全相同，由此看来集合类型的初始化在 Go 语言中有着相同的处理逻辑。 一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 for 循环加入哈希： hash := make(map[string]int, 26) vstatk := []string{\"1\", \"2\", \"3\", ... ， \"26\"} vstatv := []int{1, 2, 3, ... , 26} for i := 0; i \u003c len(vstak); i++ { hash[vstatk[i]] = vstatv[i] } 这里展开的两个切片 vstatk 和 vstatv 还会被编辑器继续展开，不过无论使用哪种方法，使用字面量初始化的过程都会使用 Go 语言中的关键字 make 来创建新的哈希并通过最原始的 [] 语法向哈希追加元素。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:3:1","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"运行时 当创建的哈希被分配到栈上并且其容量小于 BUCKETSIZE=8 时，Go 语言在编译阶段会使用如下方式快速初始化哈希，这也是编译器对小容量的哈希做的优化： var h *hmap var hv hmap var bv bmap h := \u0026hv b := \u0026bv h.buckets = b h.hash0 = fashtrand0() //哈希种子 除了上述特定的优化之外，只要我们使用 make 创建哈希，Go 语言编译器都会在类型检查期间将它们转换成 runtime.makemap，使用字面量初始化哈希也只是语言提供的辅助工具，最后调用的都是 runtime.makemap： func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u003e maxAlloc { hint = 0 } if h == nil { h = new(hmap) } h.hash0 = fastrand() B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 这个函数会按照下面的步骤执行： 计算哈希占用的内存是否溢出或者超出能分配的最大值； 调用 runtime.fastrand 获取一个随机的哈希种子； 根据传入的 hint 计算出需要的最小需要的桶的数量； 使用 runtime.makeBucketArray 创建用于保存桶的数组； runtime.makeBucketArray 会根据传入的 B 计算出的需要创建的桶数量并在内存中分配一片连续的空间用于存储数据： func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { base := bucketShift(b) nbuckets := base if b \u003e= 4 { nbuckets += bucketShift(b - 4) sz := t.bucket.size * nbuckets up := roundupsize(sz) if up != sz { nbuckets = up / t.bucket.size } } buckets = newarray(t.bucket, int(nbuckets)) if base != nbuckets { nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize))) last.setoverflow(t, (*bmap)(buckets)) } return buckets, nextOverflow } 当桶的数量小于 2^4 时，由于数据较少、使用溢出桶的可能性较低，会省略创建的过程以减少额外开销； 当桶的数量多于 2^4 时，会额外创建 2^(B-4) 个溢出桶； 根据上述代码，我们能确定在正常情况下，正常桶和溢出桶在内存中的存储空间是连续的，只是被 runtime.hmap 中的不同字段引用，当溢出桶数量较多时会通过 runtime.newobject 创建新的溢出桶。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:3:2","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"Map读写 哈希表作为一种数据结构，我们肯定要分析它的常见操作，首先就是读写操作的原理。哈希表的访问一般都是通过下标或者遍历进行的： _ = hash[key] for k, v := range hash { // k, v } 这两种方式虽然都能读取哈希表的数据，但是使用的函数和底层原理完全不同。前者需要知道哈希的键并且一次只能获取单个键对应的值，而后者可以遍历哈希中的全部键值对，访问数据时也不需要预先知道哈希的键。在这里我们会介绍前一种访问方式，第二种访问方式会在 range 一节中详细分析。 数据结构的写一般指的都是增加、删除和修改，增加和修改字段都使用索引和赋值语句，而删除Map中的数据需要使用关键字 delete： hash[key] = value hash[key] = newValue delete(hash, key) 除了这些操作之外，我们还会分析哈希的扩容过程，这能帮助我们深入理解哈希是如何存储数据的。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:4:0","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"访问 在编译的类型检查期间，hash[key] 以及类似的操作都会被转换成哈希的 OINDEXMAP 操作，中间代码生成阶段会在 cmd/compile/internal/gc.walkexpr 函数中将这些 OINDEXMAP 操作转换成如下的代码： v := hash[key] // =\u003e v := *mapaccess1(maptype, hash, \u0026key) v, ok := hash[key] // =\u003e v, ok := mapaccess2(maptype, hash, \u0026key) 赋值语句左侧接受参数的个数会决定使用的运行时方法： 当接受一个参数时，会使用 runtime.mapaccess1，该函数仅会返回一个指向目标值的指针； 当接受两个参数时，会使用 runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 bool 值： runtime.mapaccess1 会先通过哈希表设置的哈希函数、种子获取当前键对应的哈希，再通过 runtime.bucketMask 和 runtime.add 拿到该键值对所在的桶序号和哈希高位的 8 位数字。 func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize))) top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v } } } return unsafe.Pointer(\u0026zeroVal[0]) } 在 bucketloop 循环中，哈希会依次遍历正常桶和溢出桶中的数据，它会先比较哈希的高 8 位和桶中存储的 tophash，后比较传入的和桶中的值以加速数据的读写。用于选择桶序号的是哈希的最低几位，而用于加速访问的是哈希的高 8 位，这种设计能够减少同一个桶中有大量相等 tophash 的概率影响性能。 如上图所示，每一个桶都是一整片的内存空间，当发现桶中的 tophash 与传入键的 tophash 匹配之后，我们会通过指针和偏移量获取哈希中存储的键 keys[0] 并与 key 比较，如果两者相同就会获取目标值的指针 values[0] 并返回。 另一个同样用于访问哈希表中数据的 runtime.mapaccess2 只是在 runtime.mapaccess1 的基础上多返回了一个标识键值对是否存在的 bool 值： func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) { ... bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v, true } } } return unsafe.Pointer(\u0026zeroVal[0]), false } 使用 v, ok := hash[k] 的形式访问哈希表中元素时，我们能够通过这个布尔值更准确地知道当 v == nil 时，v 到底是哈希中存储的元素还是表示该键对应的元素不存在，所以在访问哈希时，更推荐使用这种方式判断元素是否存在。 上面的过程是在正常情况下，访问哈希表中元素时的表现，然而与数组一样，哈希表可能会在装载因子过高或者溢出桶过多时进行扩容，哈希表扩容并不是原子过程，在扩容的过程中保证哈希的访问是比较有意思的话题，我们在这里也省略了相关的代码，后面的小节会展开介绍。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:4:1","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"写入 当形如 hash[k] 的表达式出现在赋值符号左侧时，该表达式也会在编译期间转换成 runtime.mapassign 函数的调用，该函数与 runtime.mapaccess1 比较相似，我们将其分成几个部分依次分析，首先是函数会根据传入的键拿到对应的哈希和桶： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) h.flags ^= hashWriting again: bucket := hash \u0026 bucketMask(h.B) b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) 然后通过遍历比较桶中存储的 tophash 和键的哈希，如果找到了相同结果就会返回目标位置的地址。其中 inserti 表示目标元素的在桶中的索引，insertk 和 val 分别表示键值对的地址，获得目标地址之后会通过算术计算寻址获得键值对 k 和 val： var inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointer bucketloop: for { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil { inserti = \u0026b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if !alg.equal(key, k) { continue } val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf } 上述的 for 循环会依次遍历正常桶和溢出桶中存储的数据，整个过程会分别判断 tophash 是否相等、key 是否相等，遍历结束后会从循环中跳出。 如果当前桶已经满了，哈希会调用 runtime.hmap.newoverflow 创建新桶或者使用 runtime.hmap 预先在 noverflow 中创建好的桶来保存数据，新创建的桶不仅会被追加到已有桶的末尾，还会增加哈希表的 noverflow 计数器。 if inserti == nil { newb := h.newoverflow(t, b) inserti = \u0026newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } typedmemmove(t.key, insertk, key) *inserti = top h.count++ done: return val } 如果当前键值对在哈希中不存在，哈希会为新键值对规划存储的内存地址，通过 runtime.typedmemmove 将键移动到对应的内存空间中并返回键对应值的地址 val。如果当前键值对在哈希中存在，那么就会直接返回目标区域的内存地址，哈希并不会在 runtime.mapassign 这个运行时函数中将值拷贝到桶中，该函数只会返回内存地址，真正的赋值操作是在编译期间插入的： 00018 (+5) CALL runtime.mapassign_fast64(SB) 00020 (5) MOVQ 24(SP), DI ;; DI = \u0026value 00026 (5) LEAQ go.string.\"88\"(SB), AX ;; AX = \u0026\"88\" 00027 (5) MOVQ AX, (DI) ;; *DI = AX runtime.mapassign_fast64 与 runtime.mapassign 函数的逻辑差不多，我们需要关注的是后面的三行代码，其中 24(SP) 是该函数返回的值地址，我们通过 LEAQ 指令将字符串的地址存储到寄存器 AX 中，MOVQ 指令将字符串 \"88\" 存储到了目标地址上完成了这次哈希的写入。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:4:2","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"扩容 前面在介绍哈希的写入过程时其实省略了扩容操作，随着哈希表中元素的逐渐增加，哈希的性能会逐渐恶化，所以我们需要更多的桶和更大的内存保证哈希的读写性能： func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again } ... } runtime.mapassign 函数会在以下两种情况发生时触发哈希的扩容： 装载因子已经超过 6.5； 哈希使用了太多溢出桶； $$ 装载因子=元素数量÷桶数量 $$ 不过因为 Go 语言哈希的扩容不是一个原子的过程，所以 runtime.mapassign 还需要判断当前哈希是否已经处于扩容状态，避免二次扩容造成混乱。 根据触发的条件不同扩容的方式分成两种，如果这次扩容是溢出的桶太多导致的，那么这次扩容就是等量扩容 sameSizeGrow，sameSizeGrow 是一种特殊情况下发生的扩容，当我们持续向哈希中插入数据并将它们全部删除时，如果哈希表中的数据量没有超过阈值，就会不断积累溢出桶造成缓慢的内存泄漏。runtime: limit the number of map overflow buckets 引入了 sameSizeGrow 通过复用已有的哈希扩容机制解决该问题，一旦哈希中出现了过多的溢出桶，它会创建新桶保存数据，垃圾回收会清理老的溢出桶并释放内存。 扩容的入口是 runtime.hashGrow： func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil h.extra.nextOverflow = nextOverflow } 哈希在扩容的过程中会通过 runtime.makeBucketArray 创建一组新桶和预创建的溢出桶，随后将原有的桶数组设置到 oldbuckets 上并将新的空桶设置到 buckets 上，溢出桶也使用了相同的逻辑更新，下图展示了触发扩容后的哈希： 我们在 runtime.hashGrow 中还看不出来等量扩容和翻倍扩容的太多区别，等量扩容创建的新桶数量只是和旧桶一样，该函数中只是创建了新的桶，并没有对数据进行拷贝和转移。哈希表的数据迁移的过程在是 runtime.evacuate 中完成的，它会对传入桶中的元素进行再分配。 func evacuate(t *maptype, h *hmap, oldbucket uintptr) { b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.v = add(x.k, bucketCnt*uintptr(t.keysize)) y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.v = add(y.k, bucketCnt*uintptr(t.keysize)) runtime.evacuate 会将一个旧桶中的数据分流到两个新桶，所以它会创建两个用于保存分配上下文的 runtime.evacDst 结构体，这两个结构体分别指向了一个新桶： 如果这是等量扩容，那么旧桶与新桶之间是一对一的关系，所以两个 runtime.evacDst 只会初始化一个。而当哈希表的容量翻倍时，每个旧桶的元素会都分流到新创建的两个桶中，这里仔细分析一下分流元素的逻辑： for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) v := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, v = i+1, add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) { top := b.tophash[i] k2 := k var useY uint8 hash := t.key.alg.hash(k2, uintptr(h.hash0)) if hash\u0026newbit != 0 { useY = 1 } b.tophash[i] = evacuatedX + useY dst := \u0026xy[useY] if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.v = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top typedmemmove(t.key, dst.k, k) typedmemmove(t.elem, dst.v, v) dst.i++ dst.k = add(dst.k, uintptr(t.keysize)) dst.v = add(dst.v, uintptr(t.valuesize)) } } ... } 只使用哈希函数是不能定位到具体某一个桶的，哈希函数只会返回很长的哈希，例如：b72bfae3f3285244c4732ce457cca823bc189e0b，我们还需一些方法将哈希映射到具体的桶上。我们一般都会使用取模或者位操作来获取桶的编号，假如当前哈希中包含 4 个桶，那么它的桶掩码就是 0b11(3)，使用位操作就会得到 3， 我们就会在 3 号桶中存储该数据： 0xb72bfae3f3285244c4732ce457cca823bc189e0b \u0026 0b11 #=\u003e 0 如果新的哈希表有 8 个桶，在大多数情况下，原来经过桶掩码 0b11 结果为 3 的数据会因为桶掩码增加了一位变成 0b111 而分流到新的 3 号和 7 号桶，所有数据也都会被 runtime.typedmemmove 拷贝到目标桶中： runtime.evacuate 最后会调用 runtime.advanceEvacuationMark 增加哈希的 nevacuate 计数器并在所有的旧桶都被分流后清空哈希的 oldbuckets 和 oldoverflow： func advanceEvacuationMark(h *hmap, t *maptype, newbit uintptr) { h.nevacuate++ stop := h.nevacuate + 1024 if stop \u003e newbit { stop = newbit } for h.nevacuate != stop \u0026\u0026 bucketEvacuated(t, h, h.nevacuate) { h.nevacuate++ } if h.nevacuate == newbit { // newbit == # of oldbuckets h.oldbuckets = nil if h.extra != nil { h.extra.oldoverflow = nil } h.flags \u0026^= sameSizeGrow } } 之前在分析哈希表访问函数 runtime.mapaccess1 时其实省略了扩容期间获取键值对的逻辑，当哈希表的 oldbuckets 存在时，会先定位到旧桶并在该桶没有被分流时从中获取键值对。 func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... alg := t.key.alg hash := alg.hash(key, uintptr(h.ha","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:4:3","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"删除 如果想要删除哈希中的元素，就需要使用 Go 语言中的 delete 关键字，这个关键字的唯一作用就是将某一个键对应的元素从哈希表中删除，无论是该键对应的值是否存在，这个内建的函数都不会返回任何的结果。 在编译期间，delete 关键字会被转换成操作为 ODELETE 的节点，而 cmd/compile/internal/gc.walkexpr 会将 ODELETE 节点转换成 runtime.mapdelete 函数簇中的一个，包括 runtime.mapdelete、mapdelete_faststr、mapdelete_fast32 和 mapdelete_fast64： func walkexpr(n *Node, init *Nodes) *Node { switch n.Op { case ODELETE: init.AppendNodes(\u0026n.Ninit) map_ := n.List.First() key := n.List.Second() map_ = walkexpr(map_, init) key = walkexpr(key, init) t := map_.Type fast := mapfast(t) if fast == mapslow { key = nod(OADDR, key, nil) } n = mkcall1(mapfndel(mapdelete[fast], t), nil, init, typename(t), map_, key) } } 这些函数的实现其实差不多，我们挑选其中的 runtime.mapdelete 分析一下。哈希表的删除逻辑与写入逻辑很相似，只是触发哈希的删除需要使用关键字，如果在删除期间遇到了哈希表的扩容，就会分流桶中的元素，分流结束之后会找到桶中的目标元素完成键值对的删除工作。 func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { ... if h.growing() { growWork(t, h, bucket) } ... search: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break search } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) k2 := k if !alg.equal(key, k2) { continue } *(*unsafe.Pointer)(k) = nil v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) *(*unsafe.Pointer)(v) = nil b.tophash[i] = emptyOne ... } } } 我们其实只需要知道 delete 关键字在编译期间经过类型检查和中间代码生成阶段被转换成 runtime.mapdelete 函数簇中的一员，用于处理删除逻辑的函数与哈希表的 runtime.mapassign 几乎完全相同，不太需要刻意关注。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:4:4","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["Golang"],"content":"小结 Go 语言使用拉链法来解决哈希碰撞的问题实现了哈希表，它的访问、写入和删除等操作都在编译期间转换成了运行时的函数或者方法。哈希在每一个桶中存储键对应哈希的前 8 位，当对哈希进行操作时，这些 tophash 就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储 8 个键值对，一旦当前哈希的某个桶超出 8 个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。 ","date":"2022-09-20","objectID":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/:5:0","tags":["Golang","源码分析"],"title":"Go底层之Map实现原理","uri":"/go%E5%BA%95%E5%B1%82%E4%B9%8Bmap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"categories":["深入剖析Kubernetes"],"content":"01 | 预习篇 · 小鲸鱼大事记（一）：初出茅庐 Cloud Foundry开启PaaS为核心构建平台层服务能力的变革 PaaS在当时被接纳的主要原因是提供了“应用托管”的能力，当时用户普遍用法是租AWS或者OpenStack虚拟机，像管理物理机一样，用脚本/手工方式部署应用，导致了云端环境和本地环境不一致，PaaS项目通过打包和分发机制，Cloud Foundry为每种主流语言都定义了一种打包格式，使用cf push命令上传到云上Cloud Foundry存储中，然后通过调度器将应用调度到虚拟机上启动，并且也提供Cgroups和Namespace机制为应用单独创建一个“沙盒”的隔离环境——这，正是 PaaS 项目最核心的能力。 而这些 Cloud Foundry 用来运行应用的隔离环境，或者说“沙盒”，就是所谓的“容器” dotCloud开源Docker容器项目 Docker项目的实现，本质也是同样使用Cgroup和Namespace实现的\"沙盒\"，但是Docker有着另外的功能——Docker镜像 凭借着Docker镜像的打包方式比PaaS平台便捷的优点： 无需为每种语言，每个框架维护一个打好的包 无需做很多修改和配置工作才能运行起来 在2014年迅速占领了所有云计算领域头条技术 ","date":"2022-07-29","objectID":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/:1:0","tags":["云原生","Kubernetes"],"title":"深入剖析Kubernetes之一（预习篇）","uri":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/"},{"categories":["深入剖析Kubernetes"],"content":"02 | 预习篇 · 小鲸鱼大事记（二）：崭露头角 Docker 项目在短时间内迅速崛起的三个重要原因： Docker 镜像通过技术手段解决了 PaaS 的根本性问题； Docker 容器同开发者之间有着与生俱来的密切关系； PaaS 概念已经深入人心的完美契机。 ","date":"2022-07-29","objectID":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/:2:0","tags":["云原生","Kubernetes"],"title":"深入剖析Kubernetes之一（预习篇）","uri":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/"},{"categories":["深入剖析Kubernetes"],"content":"03 | 预习篇 · 小鲸鱼大事记（三）：群雄并起 CoreOS 是一个基础设施领域创业公司。 它的核心产品是一个定制化的操作系统，用户可以按照分布式集群的方式，管理所有安装了这个操作系统的节点。从而，用户在集群里部署和管理应用就像使用单机一样方便了。 Docker 项目发布后，CoreOS 公司很快就认识到可以把“容器”的概念无缝集成到自己的这套方案中，从而为用户提供更高层次的 PaaS 能力。所以，CoreOS 很早就成了 Docker 项目的贡献者，并在短时间内成为了 Docker 项目中第二重要的力量。 然而，这段短暂的蜜月期到 2014 年底就草草结束了。CoreOS 公司以强烈的措辞宣布与 Docker 公司停止合作，并直接推出了自己研制的 Rocket（后来叫 rkt）容器。 这次决裂的根本原因，正是源于 Docker 公司对 Docker 项目定位的不满足。Docker 公司解决这种不满足的方法就是，让 Docker 项目提供更多的平台层能力，即向 PaaS 项目进化。而这，显然与 CoreOS 公司的核心产品和战略发生了严重冲突。 相较于 CoreOS 是依托于一系列开源项目（比如 Container Linux 操作系统、Fleet 作业调度工具、systemd 进程管理和 rkt 容器），一层层搭建起来的平台产品，Swarm 项目则是以一个完整的整体来对外提供集群管理功能。而 Swarm 的最大亮点，则是它完全使用 Docker 项目原本的容器管理 API 来完成集群管理，比如： 单机 Docker 项目： $ docker run \"我的容器\" 多机 Docker 项目： $ docker run -H \"我的 Swarm 集群 API 地址\" \"我的容器\" 所以在部署了 Swarm 的多机环境下，用户只需要使用原先的 Docker 指令创建一个容器，这个请求就会被 Swarm 拦截下来处理，然后通过具体的调度算法找到一个合适的 Docker Daemon 运行起来。 后来，Docker又对Fig项目进行收购，Fig项目是第一次提出“容器编排”的项目，衍生出了Compose。 直到Google Kubernetes项目的开源… ","date":"2022-07-29","objectID":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/:3:0","tags":["云原生","Kubernetes"],"title":"深入剖析Kubernetes之一（预习篇）","uri":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/"},{"categories":["深入剖析Kubernetes"],"content":"04 | 预习篇 · 小鲸鱼大事记（四）：尘埃落定 随着Docker项目的爆火，大量网络、存储、监控、CI/CD甚至UI项目纷纷出台，也涌现了很多Rancher、Tutum这样在开源与商业上均取得了巨大成功的创业公司。 Docker项目兴起的时候，Google也推出了经历过生产环境验证的Linux容器：Imctfy，然而面对Docker的崛起，Google向Docker表示了合作愿望，共同推进container runtime项目作为Docker项目的核心依赖，但Docker公司并没有认同，在不久后发布了容器运行时库Libcontainer，但匆忙的重构导致了代码阅读性差、可维护性不强的缺点，开始让社区叫苦不迭。 于是，2015年由Docker牵头，将Libcontainer捐出，衍生出RunC的项目，交由一个完全中立的基金会管理，以RunC为依据，大家共同制定一套容器和镜像的标准和规范。这就是OCI（Open Container Initiative），OCI旨在将容器运行时和镜像的实现从Docker项目中完全剥离出来，改善了Docker在技术上一家独大的现状，给其他玩家提供了不依赖于Docker构建各自平台层能力提供了可能。 但Docker并不担心与OCI的威胁，也因本身Docker已经是容器生态的事实标准而无心推动标准建设。于是Google、RedHat等共同牵头发起了名为CNCF（Cloud Native Computing Foundation）的基金会，以Kubernetes为基础，建立一个独立基金会主导的平台级社区来对抗Docker公司为核心的容器商业生态。 面对Kubernetes社区的崛起和壮大，Docker放弃了开源社区而专注于商业化转型，从2017年开始，Docker将容器运行时部分Containerd捐赠给CNCF社区，并将Docker项目改名为Moby，交由社区维护。 ","date":"2022-07-29","objectID":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/:4:0","tags":["云原生","Kubernetes"],"title":"深入剖析Kubernetes之一（预习篇）","uri":"/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes%E4%B9%8B%E4%B8%80%E9%A2%84%E4%B9%A0%E7%AF%87/"},{"categories":["KubeEdge"],"content":"背景 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:1:0","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"云原生容器网络发展阶段 第一阶段：Docker 容器网络，在 Docker 出现之后，也有自己的 4 种容器网络模型，比如 Host 模式、Container 模式，None 模式以及 Bridge 模式。但原生 Docker 容器无法解决容器之间的跨级通信问题，后来 Docker 推出 CNM 以及对应的实现 libnetwork 解决了这个问题。 第二阶段：容器网络接口(CNI), 后来由于各种原因 Kubernetes 主推的 CNI 热度反超了 CNM，CNI 是一个接口更简单、而且兼容性更高的容器网络接口规范。 第三阶段: 服务网格 + CNI, 随着服务网络的发展，它与 CNI 进行了配合，一些服务网格的插件，会在每个 pod 启动时往 pod 里注入 Sidecar 代理，来提供 4 层或 7 层的流量治理功能。 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:1:1","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"Kubernetes服务发现 Kubernetes 服务发展其实与容器网络是依赖的关系，首先用户会通过 Deployment 创建一组应用的后端实例对其进行管理。但 Pod 的生命周期是非常短暂的，可能会随着 Pod 更新升级或迁移等，它的 Pod IP 都会发生变化，这个现象称之为 Pod IP 的漂移。 为了解决这个问题, Kubernetes 社区提出了 Service 的概念，每个 Service 都会对应到一组后端的一个应用实例上，通过提供恒定不变的 Cluster IP 来解决 Pod IP 漂移的问题，同时也提供了 proxy 组件，基于控制面提供的一些信息维护 Cluster IP 到 Pod IP 的转换规则。当 Client 需要访问该服务时，一般只需要访问这个不变的 Cluster IP 即可。这个流量会经过本机的网络栈，被替换成了 mysql 后端实例的 Pod IP，通过容器网络请求发送。 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:1:2","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"边缘场景下的挑战 边缘计算细分领域众多，互操作性差 边云通信网络质量低，时延高，且边缘经常位于私有网络，难以实现双向通信 边缘资源受限，需要轻量化的组件管理运行边缘应用 边缘离线时，需要具备业务自治和本地故障恢复等能力 边缘节点高度分散，如何高效管理，降低运维成本 如何对异构资源进行标准化管理和灵活配置 以上这些关键挑战，边缘计算平台 KubeEdge 均可以实现，也解决了基本上所有的问题。但除了这些问题外，还有一些其他问题，举个例子：比如边缘有一个视频流应用，需要与云上的 AI 应用进行交互。首先边缘的网络是无法直接与云上网络互相连通的，所以无法从边缘对云上进行访问。不过这个问题其实可以通过给云上的 AI 应用配置一个公网 IP 来解决，但如果云上的每一个应用都配置一个公网 IP，那 IP 将无法收敛。而且云上的应用想要主动访问边缘的应用，其实也是做不到的，因为边缘上的应用一般都处于私网里，它一般不会有公共 IP，所以就无法做到正确路由和双向通信。 总的来说，有以下几个问题： 边云网络割裂，微服务之间无法跨子网直接通信 边缘侧缺少服务发现能力 边缘环境下组网配置管理复杂 基于以上的问题，EdgeMesh 应运而生。 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:1:3","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"EdgeMesh ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:0","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"定义 EdgeMesh 作为 KubeEdge 集群的数据面组件，为应用程序提供了简单的服务发现与流量代理功能，从而屏蔽了边缘场景下复杂的网络结构。 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:1","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"设计原则 轻量化: 每个节点仅需部署一个极轻的代理组件，边缘侧无需依赖 CoreDNS、Kube-Proxy 和 CNI 插件等原生组件 云原生体验: 为 KubeEdge 集群中的容器应用提供与云原生一致的服务发现与流量转发体验 跨子网通信: 屏蔽复杂的边缘网络环境，提供容器间的跨子网边边和边云通信能力 高可靠性: 通过打洞建立点对点直连，转发效率极高；在不支持打洞时通过中继转发流量，保障服务之间的正常通讯 分层式架构: 采用分层式设计架构，各模块能够与原生组件兼容并支持动态关闭 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:2","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"实现功能 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:3","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"架构 EdgeMesh-Agent Proxier：负责配置内核的 iptables 规则，将请求拦截到 EdgeMesh 进程内 DNS：内置的 DNS 解析器，将节点内的域名请求解析成一个服务的集群 IP Traffic：基于 Go-Chassis 框架的流量转发模块，负责转发应用间的流量 Controller：通过 KubeEdge 的边缘侧 Local APIServer 能力获取 Services、Endpoints、Pods 等元数据 Tunnel-Agent：利用中继和打洞技术来提供跨子网通讯的能力 EdgeMesh-Server Tunnel-Server：与 EdgeMesh-Agent 建立连接，协助打洞以及为 EdgeMesh-Agent 提供中继能力 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:4","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"工作流程 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:5","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"实现原理 利用P2P打洞技术，来打通边缘节点间的网络 将边缘节点间的通信分为局域网和跨局域网 局域网内的通信：直接通信 跨局域网通信：打洞成功时Agent之间建立直连通道，否则通过Server中继转发 离线场景下通过EdgeMesh内部实现轻量级DNS服务器，域名请求在节点内闭环 极致轻量化，每个节点只有一个Agent P2P打洞实现（NAT） NAT类型 锥型 完全锥形（NAT1）：任何一个外部主机发送到（eAddr:ePort）的报文将会被转换后发送到（iAddr:iPort） 限制锥形（NAT2）：只有（iAddr:iPort）向特定的外部主机hAddr发送过数据，主机hAddr从任意端口发送到（eAddr:ePort）的报文将会被转发到（iAddr:iPort） 端口限制锥形（NAT3）：只有（iAddr:iPort）向特定的外部主机端口对（hAddr:hPort）发送过数据，由（hAddr:hPort）发送到（eAddr:ePort）的报文将会被转发到（iAddr:iPort） 对称型 对称NAT（NAT4）：对称式NAT把内网IP和端口到相同目的地址和端口的所有请求，都映射到同一个公网地址和端口；同一个内网主机，用相同的内网IP和端口向另外一个目的地址发送报文，则会用不同的映射（比如映射到不同的端口）。 注：NAT类型与运营商相关 结论 穿透能力只与NAT类型强相关，从上到下穿透性下降，安全性上升 一端是对称型，另一端是对称型或端口限制型则无法穿透 关于NAT，更详细的介绍请戳：https://zhuanlan.zhihu.com/p/335253159 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:6","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"官方性能测试 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:7","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"目前存在的问题 EdgeMesh目前不支持多点部署，在某些情况下会出现问题 情况1： 当连接数过大或通信流量过大时，都会导致edgemesh-server的单点故障问题 情况2： edgemesh-server 的位置会影响流量转发的延迟。如果中继服务器的位置太远，会大大增加延迟。 情况3： 在某些私有网络的情况下，edgemesh-agent 无法连接到外网的 edgemesh-server，从而导致 edgemesh-agent 无法正常工作。 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:8","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"EdgeMesh RoadMap 2021.06： EdgeMesh 项目开源 2021.09： EdgeMesh 支持微服务跨局域网边云/边边通信 2021.12： EdgeMesh 支持一键化部署 2022.03： EdgeMesh 支持 Pod IP 的流量跨边云转发 2022.06： EdgeMesh 对接标准的 Istio 进行服务治理控制 2022.09： EdgeMesh 支持跨集群服务通信 ","date":"2022-07-10","objectID":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/:2:9","tags":["KubeEdge","EdgeMesh","边缘计算"],"title":"KubeEdge组件之EdgeMesh","uri":"/kubeedge%E7%BB%84%E4%BB%B6%E4%B9%8Bedgemesh/"},{"categories":["KubeEdge"],"content":"核心理念 云边协同 双向多路复用消息通道，支持边缘节点位于私有网络（无公网IP环境） Websocket+消息封装，大幅减少通信压力，高时延下仍可正常工作 边缘离线自治 节点元数据持久化，实现节点级离线自治 节点故障恢复无需List-watch，降低网络压力，快速ready 极致轻量 重组Kubelet功能模块，极致轻量化（~10mb内存占用） 移除内嵌存储驱动，通过CSI接入 支持CRI集成Containerd、CRI-O，优化runtime资源消耗 ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:1:0","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"架构 KubeEdge总体由云上部分（CloudCore）和边缘部分（EdgeCore）构成: ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:2:0","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"云上组件 EdgeController（扩展的K8s控制器） 边缘节点管理 应用状态元数据云边同步 设备抽象API/DeviceController（扩展的K8s控制器） 接入和管理边缘设备 设备元数据（信息、状态）云边同步 CSI Driver 同步存储数据到边缘 Admission Webhook 校验进入KubeEdge对象的合法性 CloudHub WebSocket服务端，监听云端变化，缓存并发送消息到EdgeHub ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:2:1","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"边缘组件 EdgeHub WebSocket客户端，负责与云端（EdgeController）交互，同步云端资源更新；并向上报告边缘主机和设备状态变化 MetaManager 消息处理器，位于 Edged 和 Edgehub 之间，它负责向轻量级数据库 (SQLite) 存储/检索元数据 DeviceTwin 负责存储设备状态（开关值、传感器值等）到EdgeStore并将设备状态同步到云，另外为应用程序提供查询接口 EventBus 与MQTT服务器（mosquitto）交互的MQTT客户端，为其他组件提供订阅和发布功能 ServiceBus 运行在边缘的 HTTP 客户端，接受来自云上服务的请求，与运行在边缘端的 HTTP 服务器交互，提供了云上服务通过 HTTP 协议访问边缘端 HTTP 服务器的能力 Edged（Kubelet-lite） 轻量的Kubelet，用于管理容器化的应用程序 ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:2:2","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"关键能力 ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:3:0","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"支持CRI接口 早期KubeEdge集成了Docker Client，v1.0之后加入CRI，可自行选择容器运行时 通过CRI，把相关组件和容器运行时进行解耦，可实现选择适合自己的容器运行时 ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:3:1","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"支持CSI接口 Kubernetes的数据存储在云上数据中心，每个节点都能轻松访问到，并且组件与Master之间的交互采用List、Watch机制同步数据。 以云边协同为基础的KubeEdge部分节点在云上，部分节点在边缘，以List、Watch机制同步数据需要跨越云边实现List、Watch，开销很大。 KubeEdge的做法是：在云上使用CSI Driver from KubeEdge做劫持，通过CloudHub发送到边缘，真实的存储后端实际上分布在边缘。 ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:3:2","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"边缘设备管理 DeviceModel：定义设备通用的属性字段，是否只读，是否需要做数据处理 Device：定义需要接入的设备实体，会从DeviceModel继承属性字段，只要配置设备访问方式等就能实现与设备的交互 南向Mapper组件：把设备的其他协议（OPC-UA、Modbus等）转换成MQTT协议，推荐每个边缘节点以Demonset形式部署Mapper ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:3:3","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"EdgeMesh:ServiceMesh At Edge EdgeMesh作用 实现简单的服务发现和流量代理功能，从而屏蔽了边缘场景下复杂的网络结构 EdgeMesh实现原理 利用P2P技术，来打通边缘节点间网络 P2P打洞不成功情况下，通过Server中继转发 ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:3:4","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":["KubeEdge"],"content":"EdgeSite EdgeSite作用 KubeEdge默认在云端部署EdgeController和DeviceController，然后通过Websocket/Quic隧道连接云端和边缘端，通过云端一个中心来统一调度应用到特定Edge Node上运行。但是，就像Rancher K3s的应用场景，有些时候边缘端也希望运行一套完整的K8s集群，K3s的方案只是提供了一套精简的K8s集群，而Kubeedge的EdgeSite模式，除了运行K8s集群之外，还提供了对IoT设备的适配和支持。 有些场景用户需要在边缘运行一个独立的 Kubernetes 集群来获得完全控制并提高离线调度能力，有两种情况用户需要这样做： CDN场景 CDN 站点通常遍布全球，无法保证边端节点间网络连接和质量；另一个因素是部署在 CDN 边缘的应用程序通常不需要与中心交互。对于那些在 CDN 资源中部署边缘集群的人来说，他们需要确保集群在没有与中央云连接的情况下也能正常工作。 用户需要部署资源有限且大部分时间离线运行的边缘环境 在一些物联网场景中，用户需要部署一个边缘环境并离线运行。 对于这些用例，需要一个独立的、完全受控的、轻量级的 Edge 集群。通过集成 KubeEdge 和标准 Kubernetes，这个 EdgeSite 使客户能够运行一个高效的 Kubernetes 集群来进行 Edge/IOT 计算。 From:https://www.bookstack.cn/read/kubeedge/1171574c81cee03f.md ","date":"2022-06-27","objectID":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/:3:5","tags":["KubeEdge","边缘计算"],"title":"KubeEdge架构及其核心组件","uri":"/kubeedge%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%85%B6%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"categories":null,"content":" Leo leo@leosgo.com · myleo1 · My Site ","date":"2022-06-26","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"个人信息 男 云平台研发工程师（Golang） ","date":"2022-06-26","objectID":"/about/:0:1","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"教育经历 硕士，浙江工商大学，信息与通信工程，2020.9~2023.6 ","date":"2022-06-26","objectID":"/about/:0:2","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"工作经历 杭州领克信息科技有限公司，研发部，IoT后端开发工程师，2020.6~2022.4 网易（杭州）网络有限公司，伏羲实验室，云平台研发工程师，2022.5~ ","date":"2022-06-26","objectID":"/about/:0:3","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"技能清单 ★★★ Golang ★★★ Kubernetes ★★★ Docker ★★★ MySQL ★★☆ PostgreSQL ★★☆ Redis ","date":"2022-06-26","objectID":"/about/:0:4","tags":null,"title":"About","uri":"/about/"}]